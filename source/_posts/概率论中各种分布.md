---
title: 概率论中各种分布
date: 2023-10-24 09:08:47
tags: Mathematic
description: the record of various distribution also my mid-term examination. 
mathjax: true
---
![img](file:///C:\Users\24964\Documents\Tencent Files\2496438098\nt_qq\nt_data\Pic\2023-10\Ori\78e67b20b808405a7fe8f2e1746f58c6.png)

### 离散分布

#### Bernoulli 分布(Bernoulli Distribution)

##### 符号：$X \sim B(1, p)$

##### 概率：$P(X = k) = p^{k}(1-p)^{1-k}$

##### 期望：$E(X) = 0\times (1-p) + 1 \times p = p$ 

##### 方差：$D(X) = E(X^{2}) - E(X)^{2} = p - p^2 = p(1-p)$

##### 性质：

##### 应用：

#### 二项分布(Binomial Distribution)

##### 符号：$X\sim B(n, p)$

##### 概率：

\begin{aligned}
P(X = k) = \begin{pmatrix}

n \\
k
\end{pmatrix} (1-p)^{n - k}p^k
\end{aligned}

##### 期望：

\begin{aligned}
E(X)= \sum\limits_{k = 0}^{n}kp(X = k) =\sum\limits_{k = 0}^{n} k\begin{pmatrix}
n \\
k
\end{pmatrix} (1-p)^{n - k}p^k \\
= \sum\limits_{k = 1}^{n}\begin{pmatrix} n - 1\\ m - 1\end{pmatrix}p^{k}(1-p)^{n - k} \quad \quad \quad \\
= \sum\limits_{k = 0}^{n - 1}np\begin{pmatrix}n - 1 \\ k \end{pmatrix} p^{k}(1-p)^{n - 1 - k} \quad \\
= np\times (p + (1 - p))^{n - 1} \quad \quad \quad \quad \quad  \\
= np \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad
\end{aligned}

##### 方差：

\begin{aligned}
D(X) = E(X^{2}) - E(X)^{2} =E(X(X-1)+X) - E(X)^{2} \\
=E(X(X-1)) + E(X) - E(X)^{2} \quad \quad \quad \quad  \\

E(X(X-1)) = \sum\limits_{k = 0}^{n}k(k - 1)\begin{pmatrix} n \\ k\end{pmatrix} p^{k}(1-p)^{n - k} \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad  \\ = n(n - 1)\sum\limits_{k = 2}^{n} \begin{pmatrix} n - 2\\ k - 2\end{pmatrix} p^{k}(1 - p)^{n - l} \quad \quad \\
= n(n - 1)\sum\limits_{k = 0}^{n - 2}\begin{pmatrix} n - 2 \\ k \end{pmatrix} p^{k + 2}(1-p)^{n - 2 - k} \\
= n(n - 1) p^{2} (1 + (1 - p))^{n - 2} \ \ \ \  \quad \quad \quad \quad  \\
= n(n - 1)p^{2} \quad \quad \quad \quad \quad \quad \quad \quad \quad \ \ \ \quad \quad \\

D(X) = n(n -1)p^{2} + np - n^{2}p^{2}  = np(1-p) \quad \quad \quad
\end{aligned}

##### 性质：

##### 应用：

1. 一段时间内物理实验仪器捕获的粒子数目。
2. 一段时间内计算机病毒的入侵数。
3. 一本书中的错字数。

#### 多项分布(Multinomial Distribution)

多项分布(Multinomial Distribution)，它是二项分布的推广。二项分布的试验结果只有两个(成功和失败)，而多项分布的试验结果则多于两个。

##### 联合概率函数：

$$
\begin{aligned}
P(X_1 = x_1, X_2 = x_2, ..., X_k = x_k) = \dfrac{n!}{x_1!x_2!...x_k!} p_1^{x_1}p_2^{x_2}...p_{k}^{x_k}
\end{aligned}
$$

多项分布对于每一个结果都有均值和方差，分别为：

##### 期望：

$$
\begin{aligned}
E(X_i) = np_i
\end{aligned}
$$

##### 方差：

$$
D(X_i) = np_i(1-p_i)
$$

#### 泊松分布(Possion Distribution)

##### 符号：$X\sim P(\lambda)$

##### 概率：$P(X = x) = \dfrac{e^{-\lambda}\lambda^{x} }{x!}$

证明：
由 $\lambda$ 的定义，单位时间内随机事件发生 $\lambda$ 次，并且每一次事件发生都是独立的，和时间没有关系的。

所以如果我们将单位单位时间划分为 n 份，当 n 趋近于正无穷的时候，我们可以认为每一段时间内事件发生的次数是均匀的。所以每一段时间事件发生的概率都是 $\dfrac{\lambda}{n}$ 
$$
\begin{aligned}
P(X = x) = \lim\limits_{n \to +\infty}\begin{pmatrix} n \\ x\end{pmatrix} (\dfrac{\lambda}{n})^{x}(1 - \dfrac{\lambda}{n})^{n - x} = \dfrac{\lambda^{k}}{k!}e^{-\lambda}
\end{aligned}
$$

##### 期望：

$$
\begin{aligned}
E(X) &= \sum\limits_{k=0}^{+\infty} k \dfrac{\lambda^{k}}{k!}e^{-\lambda} \\
&= \lambda e^{-\lambda} \sum\limits_{k = 1}^{+\infty} \dfrac{\lambda^{k - 1}}{(k - 1)!} \\
&= \lambda e^{-\lambda} e^{\lambda} \\
&= \lambda
\end{aligned}
$$

##### 方差：

$$
\begin{aligned}
E(X^{2}) = E(X(X - 1) + X) = E(X(X-1)) + E(X) \\
\end{aligned}
$$

$$
\begin{aligned}

E(X(X - 1)) &= \sum\limits_{k = 1}^{+\infty} k(k - 1) \dfrac{\lambda^{k}}{k!}e^{-\lambda} \\
&=\sum\limits_{k = 2}^{+\infty}\dfrac{\lambda^{k}}{(k - 2)!}e^{-\lambda} \\
&= \lambda^{2}e^{-\lambda}\sum\limits_{k = 0}^{+\infty}\dfrac{\lambda^{k}}{k!}\\
&= \lambda^{2}
\end{aligned}
$$


$$
\begin{aligned}
D(X) &= E(X^{2}) - E(X)^{2} \\
&= E(X(X - 1)) + E(X) - E(X)^{2} \\
&= \lambda^{2} + \lambda - \lambda^{2}\\
&= \lambda
\end{aligned}
$$

##### 性质：

1. 伯努利分布是二项分布的特殊情况，当 n = 1 的时候，二项分布变为伯努利分布。泊松分布可以被看作是二项分布的极端情况，在试验次数非常多或者成功概率非常小的情况下，可以近似为泊松分布。指数分布也可以由泊松分布推导而来。
2. 泊松分布中 $\lambda$ 表示单位时间内随机事件的平均发生次数。在一个特定时间内，某一个事件都会在任意时刻发生(前提是，每次发生都是独立的，并且跟事件没有关系)。

##### 应用：

泊松分布是用来描述在给定时间段内随机事件发生次数的分布。例如一天之间收到的电子邮件数量。

#### 几何分布(Geometric Distribution)

##### 符号：$X\sim G(p)$

##### 概率：$P(X = k) = (1-p)^{k - 1}p$

##### 期望：

$$
\begin{aligned}
E(X) &= \sum\limits_{k = 1}^{+\infty} k \cdot (1-p)^{k - 1}p \\
&=p \sum\limits_{k = 1}^{+\infty} \left( \int k \cdot (1-p)^{k - 1}\right)' \\
&= p \left(-\sum\limits_{k = 1}^{+\infty}(1-p)^{k} \right)' \\
&= p \cdot \dfrac{1}{p^{2}} \\
&= \dfrac{1}{p}
\end{aligned}
$$
##### 方差：

$$
\begin{aligned}
D(X) &= E(X^{2}) - E(X)^{2} \\
&= \sum\limits_{k = 1}^{+\infty} k^{2}(1 - p)^{k - 1}p - \dfrac{1}{p^{2}} \\
&= p \left[\sum\limits_{k = 1}^{+\infty}(k+ 1)kq^{k - 1} - \sum\limits_{k = 1}^{+\infty} kq^{k - 1} \right] - \dfrac{1}{p^{2}} \\
&= \dfrac{1 - p}{p^{2}}
\end{aligned}
$$

##### 性质：

#### 超几何分布(Hypergeometric Distribution)

##### 符号：

##### 概率：$P(X = k) = \frac{\begin{pmatrix} M \\ k\end{pmatrix} \begin{pmatrix} N - M \\ n - k\end{pmatrix} }{\begin{pmatrix} N \\ M\end{pmatrix} }, k \leq \min(n, M) = k_1$

##### 期望：

$$
\begin{aligned}
E(X) &= \sum\limits_{k = 1}^{k_1} k \cdot \frac{\begin{pmatrix} M \\ k\end{pmatrix} \begin{pmatrix} N - M \\ n - k\end{pmatrix}}{\begin{pmatrix} N \\ M\end{pmatrix}} \\
&= \sum\limits_{k = 1}^{k_1} \begin{pmatrix} N - M \\ n - k\end{pmatrix}\times \frac{\frac{M(M - 1)!}{(k - 1)!(M - k)!}}{\frac{N(N - 1)!}{n(n - 1)!(N-n)!}} \\
&= \dfrac{nM}{N}\sum\limits_{k = 1}^{k_1} \frac{\begin{pmatrix} M - 1 \\ k - 1\end{pmatrix}\begin{pmatrix}N - M \\ n - k \end{pmatrix} }{\begin{pmatrix} N - 1\\ n - 1\end{pmatrix}}\\
&= \dfrac{nM}{N} \frac{\sum\limits_{k = 1}^{k_1} \begin{pmatrix} M - 1 \\ k - 1\end{pmatrix}\begin{pmatrix}N - 1 - (M - 1) \\ n - 1 - (k - 1) \end{pmatrix}}{\begin{pmatrix} N - 1 \\ n - 1\end{pmatrix}} \\
&= \dfrac{nM}{N}
\end{aligned}
$$

##### 方差：

$$
E(X^{2})= E(X(X - 1) + X) = E(X(X - 1)) + E(X)
$$

$$
\begin{aligned}
E(X(X - 1))) &= \sum\limits_{k = 0}^{k_1} k(k - 1) \frac{\begin{pmatrix}M \\k \end{pmatrix} \begin{pmatrix} N - M \\ n - k\end{pmatrix}}{\begin{pmatrix} N \\ n\end{pmatrix}} \\
&= \frac{nM(n - 1)(M - 1)}{N(N - 1)} \sum\limits_{k = 2}^{k_1} \frac{\begin{pmatrix} M - 2 \\ k - 2\end{pmatrix} \begin{pmatrix} N - M \\ n - k\end{pmatrix}}{\begin{pmatrix} N - 2 \\ n - 2\end{pmatrix}} \\
&= \frac{nM(n - 1)(M - 1)}{N(N - 1)}
\end{aligned}
$$

$$
\begin{aligned}
D(X) = E(X(X - 1))) + E(X) - E(X)^{2}  = \frac{nM(N - M)(N - n)}{N^{2}(N - 1)}
\end{aligned}
$$



##### 性质：

1. 当总物品个数远远大于选的个数，或者总物品个数区域无穷大的时候，超几何分布可以近似为二项分布。
2. 

##### 应用：

#### 负二项分布(帕斯卡分布, Negative Binomial Distribution, Pascal Distribution)

##### 符号：$X \sim \text{Pascal}(n, p)$

##### 概率：$P(X = x) = \begin{pmatrix} x - 1\ \\ r - 1\end{pmatrix}p^{r}(1  -p)^{x - r}$

![image-20231024232853695](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231024232853695.png)

##### 期望：

$$
\begin{aligned}
E(X) &= \sum\limits_{x = r}^{+\infty} x f(x) \\
&= \sum\limits_{x = r}^{+\infty} x\begin{pmatrix} x - 1 \\ r - 1\end{pmatrix} p^{r}(1 - p)^{x - r} \\
&= \frac{r}{p} \sum\limits_{x = r}^{+\infty} \begin{pmatrix}x  \\ r \end{pmatrix} p^{r + 1} (1 - p)^{x  - r} \\
&= \frac{rp}{1 - p}
\end{aligned}
$$
##### 方差：

$$
\begin{aligned}
E(X^{2}) &= \sum\limits_{x = r}^{+\infty} x^{2}f(x) \\
&= \sum\limits_{x = r}^{+\infty} x^{2} \begin{pmatrix}x - 1 \\ r-  1 \end{pmatrix}p^{r}(1 - p)^{x - r} \\
&= \frac{r}{p} \sum\limits_{x = r}^{+\infty} x\begin{pmatrix} x \\ r\end{pmatrix}p^{r + 1} (1 - p)^{x- r} \\
&= \frac{r}{p} \left[\sum\limits_{x = r}^{+\infty}(x + 1)\begin{pmatrix} x  \\ r\end{pmatrix} p^{r+ 1}(1 - p)^{x - r} - \sum\limits_{x = r}^{+\infty}\begin{pmatrix} x \\ r\end{pmatrix} p^{r+ 1}(1 - p)^{x - r}\right] \\
&= \frac{r}{p}(\frac{r + 1}{p} - 1) \\
&= \frac{r(r - p + 1)}{p^{2}}
\end{aligned}
$$

$$
\begin{aligned}
D(X) = E(X^{2}) - E(X)^{2} = \frac{r(1 - p)}{p^{2}}
\end{aligned}
$$

##### 性质：

Binomial 分布和 Negative Binomial 分布都是多次重复的 Bernoulli 实验。

Binomial关注的是，重复Bernoulli实验成功概率为p，条件为总共实验N次，随机变量为N次实验中成功实验次数k（k∈Z,k∈[0,N]），该随机变量[概率分布为Binomial分布。

Negative Binomial关注的是，重复Bernoulli实验成功概率为p，条件为累计出现r次失败，随机变量为成功实验次数k（k∈Z,k∈[0,+∞)），该随机变量的概率分布为Negative Binomial分布。

Binomial和Negative Binomial分布的随机变量都是成功实验次数，条件不同。从定义上来看，”负“可以理解为站在失败次数的角度看成功。

##### 应用：

#### 伽马-泊松分布(Gamma-Poisson Distribution)

##### 符号：$X \sim \text{gamma-Poisson}(\alpha, \beta)$

##### 概率密度函数：

$$
\begin{aligned}
f(x) = \dfrac{\Gamma(x + \beta) \alpha^{x}}{\Gamma(\beta)(1+\alpha)^{\beta + x}x!}
\end{aligned}
$$

![image-20231024233912306](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231024233912306.png)

##### 期望：

$$
E(X) = \alpha\beta
$$

##### 方差：

$$
\begin{aligned}
D(X) = \alpha \beta + \alpha^{2}\beta
\end{aligned}
$$

##### 性质：

1. 做变换：$\alpha = (1 - p) / p, \beta = n$，就得到 Pascal 分布

#### Zeta 分布(Zeta Distribution)

##### 符号：$X \sim \text{Zeta}(\alpha)$

##### 概率函数：

$$
\begin{aligned}
f(x) = \dfrac{1}{x^{\alpha}\sum\limits_{i = 1}^{+\infty}(1/i)^{\alpha}} \quad x = 1, 2, 3, ...
\end{aligned}
$$

![image-20231026215915467](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231026215915467.png)

##### 累计分布函数

$$
\begin{aligned}
F(x) = P(X \leq x) = \dfrac{\sum\limits_{i = 1}^{x} (1/i)^{\alpha}}{\zeta(\alpha)} \quad x = 1, 2, ...
\end{aligned}
$$

##### 期望：

$$
\begin{aligned}
E(X) = \dfrac{\zeta(\alpha - 1)}{\zeta(\alpha)}
\end{aligned}
$$

##### 方差：

$$
\begin{aligned}
D(X) = \dfrac{\zeta(\alpha)\zeta(\alpha - 2) - \zeta(\alpha - 1)^{2}}{\zeta(\alpha)^{2}}
\end{aligned}
$$

#### Zipf 分布(齐夫定律)

##### 符号：$X \sim \text{Zipf}(\alpha, n)$

##### 概率函数：

$$
f(x) = \dfrac{1}{x^{\alpha}\sum\limits_{i = 1}^{n}(1 / i)^{\alpha}} \quad  x = 1, 2, 3, ..., n
$$

下面是 $\alpha = 1, n = 10$

![image-20231026224615881](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231026224615881.png)

我们记 $H_{n, \alpha} = \sum\limits_{i = 1}^{n} \left(\dfrac{1}{i}\right)^{\alpha}$

##### 期望：

$$
E(X) = \dfrac{H_{n, \alpha - 1}}{H_{n, \alpha}}
$$

##### 方差：

$$
D(X) = \dfrac{H_{n, \alpha - 2}H_{n, \alpha} - H_{n, \alpha}^{2}}{H_{n, \alpha}^{2}}
$$

##### 齐夫定律：

在自然语言的语料库里，一个单词出现的率与它在频
率表里的排名成反比。所以，频率最高的单词出现的频率大约是出现频率第二位的单词的2
倍，而出现频率第二位的单词侧是出现频率第四位的单词的2倍。这个定律被作为任何与幂
定律概率分布有关的事物的参考。

##### 应用 or 遵循该定律的现象：

1. 英文单词或中文汉字的出现频率：不仅适用于语料全体，也适用于单独的一篇文章
2. 网页访问频率
3. 城镇人口与城镇等级的关系
4. 收入前3%的人的收入
5. 地震震级
6. 固体破碎时的碎片大小

### 连续分布

#### 均匀分布(Uniform Distribution)

##### 符号：$X \sim U(a, b)$
##### 概率密度函数：

$$
f(x) = \begin{cases} \dfrac{1}{b - a} , a < x < b \\
0\end{cases}
$$
##### 分布函数：

$$
F(x) = \begin{cases}
\frac{x - a}{b - a}, &a < x < b \\
0,&x < a \\
1,&x > b
\end{cases}
$$

##### 期望：

$$
\begin{aligned}
E(X) &= \int_{-\infty}^{+\infty} x \cdot f(x) \mathrm{d}x \\
&= \int_{a}^{b} \dfrac{x}{b - a} \mathrm{d}x \\
&= \dfrac{a + b}{2}
\end{aligned}
$$
##### 方差：

$$
E(X^{2}) &= \int_{a}^{b} \dfrac{x^{2}}{b - a} \mathrm{d}x\\
&= \dfrac{a^{2}+ab + b^{2}}{3}
$$

$$
\begin{aligned}
D(X) &= E(X^{2}) - E(X)^{2} \\
&= \dfrac{a^{2}+ab + b^{2}}{3} - \left( \dfrac{a+b}{2}\right)^{2} \\
&= \dfrac{(b - a)^{2}}{12}
\end{aligned}
$$

##### 性质：

##### 应用：

#### 指数分布(Exponential Distribution)

指数分布一个很重要的特征就是无记忆性 $P(x > s | x > t) = P(x > s - t), s > t$ 。如果我们使用 x 表示等待的时间。那么这个式子的含义就是 **未来我还需要等到多少时间和我已经等待了多长时间没有关系**。

无记忆性的离散版本是 **几何分布。**

##### 符号：$X\sim E(\lambda)$

##### 概率密度函数：

$$
f(x) = \begin{cases}
\lambda e^{-\lambda x}, &x > 0 \\
\\
0, &x \leq 0
\end{cases}
$$

推导：

我们根据实际情况来考虑，如果一个产品的使用寿命是 T，分布函数是 $F(t)$，那么寿命大于 t 的概率为 $S(t) = 1- F(t)$

如果一个产品已经使用 t 时间，那么在 $(t, t + \Delta t)$ 这一段时间内，死亡的「风险」为:
$$
\lambda(t) = \lim\limits_{\Delta t \to 0} \dfrac{P(t \leq T \leq t + \Delta t)}{\mathrm{d}t \cdot S(t)} = \dfrac{f(t)}{S(t)} = -\dfrac{S'(t)}{S(t)} = -\dfrac{\mathrm{d}}{\mathrm{d}t}\ln(S(t))
$$
> 解释：因为我们首先需要活到这个时间，然后在这个时间段死亡，所以有 $S(t) \cdot \lambda(t) = p(T = t)$

我们称这个 $\lambda(t)$ 为风险函数（到这里还没有涉及到无记忆性，这个 $\lambda(t)$ 是一个普遍的风险函数）

如果我们要满足无记忆性，就要有 $\lambda(t) = \text{Const}$（也就是我们在每一个时间下「死亡」的概率都是等大的）

或者我们由「无记忆性」的直接式子推导：$P(T > s | T > t) = P(T > s - t) \Rightarrow P(t \leq T \leq t + \Delta t) = P(T < \mathrm{d}t) \cdot S(t)$ 也是得到 $\lambda(t) = \text{Const}$ 

所以有
$$
-\dfrac{\mathrm{d}}{\mathrm{d}t}\ln(S(t)) = \text{Const}
$$
解得 $F(t) = 1 - e^{-\text{Const} \cdot t}$

其中，$\text{Const}$ 表示每一个时间点死亡的风险大小，也就是每一个时间点死亡的概率大小。

##### 分布函数：

$$
F(x) = \begin{cases}
1 - e^{-\lambda x}, &x > 0 \\
0, &x \leq 0
\end{cases}
$$
##### 期望：

$$
\begin{aligned}
E(X) &= \int_{-\infty}^{+\infty} x \cdot f(x) \mathrm{d}x \\
&= \int_0^{+\infty} x \cdot \lambda e^{-\lambda x} \mathrm{d}x \\
&= x(-e^{-\lambda x})|_{0}^{+\infty} - \int_{0}^{+\infty} -e^{-\lambda x} \mathrm{d}x \\
&= \frac{1}{\lambda}
\end{aligned}
$$
##### 方差：

$$
\begin{aligned}
E(X^{2}) &= \int_0^{+\infty} x^{2} \cdot \lambda e^{-\lambda x} \mathrm{d}x \\
&= \int_0^{+\infty} x^{2} \mathrm{d}(-e^{-\lambda x}) \\
&= x^{2}(-e^{-\lambda x})|_{0}^{+\infty} + 2\int_0^{+\infty}xe^{-\lambda x} \mathrm{d}x \\
&= \frac{2}{\lambda^{2}}
\end{aligned}
$$

$$
D(X) = E(X^{2}) - E(X)^{2} = \frac{1}{\lambda^{2}}
$$

##### 性质：

指数分布通常用来建模持续时间，只不过指数分布能够建模的持续时间具有比较特殊的性质，也就是所谓的“无记忆性”

无记忆性：
$$

$$

##### 应用：

1. 泊松分布、指数分布、二项分布、伯努利分布之间的关系：

   当 n 趋近于无穷大时，二项分布可以近似为泊松分布；当 $\lambda$ 趋近于无穷大
   时，泊松分布可以近似为正态分布；而指数分布则是泊松分布在连续时间上的推广，因此也与泊松
   分布有一定的联系。但是，这些分布之间的应用场景和特点是不同的，需要根据实际问题选择合适
   的分布模型。

2. 

#### 正态分布(高斯分布, Normal Distribution)

##### 符号：$X\sim N(\mu, \sigma^{2})$

##### 概率密度函数：

$$
f(x) = \dfrac{1}{\sqrt{2\pi} \sigma}e^{-\frac{-(x-\mu)^{2}}{2\sigma^{2}}}(\mu \in R, \sigma > 0)
$$
##### 分布函数：

##### 期望：

$$
\begin{aligned}
E(X) &= \int_{-\infty}^{+\infty} x \cdot \frac{1}{\sqrt{2 \pi} \sigma}e^{-\frac{-(x-\mu)^{2}}{2\sigma^{2}}} \mathrm{d}x \\
&=\int_{-\infty}^{+\infty}(x - \mu + \mu) \cdot \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x - \mu)^{2}}{2\sigma^{2}}} \mathrm{d}(x - \mu)\\
&= \int_{-\infty}^{+\infty} \frac{t}{\sqrt{2\pi}\sigma}e^{-\frac{t^{2}}{2\sigma^{2}}} \mathrm{d}t + \mu \int_{-\infty}^{+\infty}\frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x - \mu)^{2}}{2\sigma^{2}}} \mathrm{d}x \\
&= 0 + \mu \\
&= \mu
\end{aligned}
$$
##### 方差：

$$
\begin{aligned}
D(X) &= \int_{-\infty}^{+\infty} x^{2} \cdot \frac{1}{\sqrt{2 \pi} \sigma}e^{-\frac{-(x-\mu)^{2}}{2\sigma^{2}}} \mathrm{d}x \\
&= \int_{-\infty}^{+\infty}(x - \mu)^{2} f(x) \mathrm{d}x + 2\mu \int_{-\infty}^{+\infty}x \cdot f(x) \mathrm{d}x - \mu^{2} \int_{-\infty}^{+\infty} f(x)\mathrm{d}x \\
&= \frac{1}{\sqrt{2\pi} \sigma}\int_{0}^{+\infty} \sqrt{t}e^{\frac{t}{2\sigma^{2}}} \mathrm{d}t + 2\mu^{2} - \mu^{2}\\
&= \sigma^{2}
\end{aligned}
$$
##### 性质：

标准正态分布：



##### 应用：

#### 多元高斯分布(Multivariate Gaussian Distribution)

##### 概率密度函数：

##### 应用：多元高斯分布的性质和应用在统计学、机器学习、信号处理和贝叶斯推断等领域中都非常重要。

#### 混合高斯分布(Mixture of Gaussian Distributions)



##### 应用：

混合高斯模型在许多领域中有广泛的应用，如模式识别、聚类分析、异常检测和图像分割。它允许建模复杂的数据分布，其中数据点可以由多个不同的分布生成，而不仅仅是单一的高斯分布。这使得混合高斯模型成为数据建模和分析中的强大工具。

#### 对数正态分布(Log-Normal Distribution)

#### 伽马分布(Gamma Distribution)

##### 符号：$X \sim Ga(\alpha, \lambda)$

##### 概率密度函数：

$$
f(x) = \begin{cases}
\dfrac{\lambda^{\alpha}}{\Gamma(\alpha)} x^{\alpha - 1}e^{-\lambda x}, &x \geq 0\\
0 & x < 0
\end{cases}
$$
##### 期望：

$$
\begin{aligned}
E(X) &= \dfrac{\lambda^{\alpha}}{\Gamma(\alpha)}\int_{0}^{+\infty} x^{\alpha} e^{-\lambda x} \mathrm{d}x \\ &= \dfrac{\lambda^{\alpha}}{\Gamma(\alpha)} \int_{0}^{+\infty} \dfrac{t^{\alpha}}{\lambda ^{\alpha + 1}}e^{-t} \mathrm{d}t \\
&= \dfrac{\Gamma(\alpha  +1)}{\Gamma(\alpha) \cdot \lambda} \\
&= \frac{\alpha}{\lambda}
\end{aligned}
$$
##### 方差：

$$
\begin{aligned}
E(X^{2}) &= \int_{0}^{+\infty} x^{2} \cdot \dfrac{\lambda^{\alpha}}{\Gamma(\alpha)} x^{\alpha - 1}e^{-\lambda x} \mathrm{d}x \\
&= \dfrac{1}{\lambda^{2}\Gamma(\alpha)} \int_0^{+\infty} t^{\alpha+1}e^{-t}\mathrm{d}t \\
&= \dfrac{\alpha(\alpha + 1)}{\lambda^{2}}
\end{aligned}
$$

$$
D(X) = E(X^{2}) - E(X)^{2}  = \dfrac{\alpha}{\lambda^{2}}
$$
##### 性质：

1. $\alpha  = 1$ 的时候，伽马分布与指数分布之间的关系就建立起来了，有 $Ga(1, \lambda ) = E(\lambda)$

2. 当 $\alpha = \dfrac{n}{2}, \lambda = \dfrac{1}{2}$ 的时候，伽马分布和卡方分布之间的关系就建立起来了，有 $Ga(\dfrac{n}{2}, \dfrac{1}{2}) = \mathcal{X}^{2}(n)$
3. 伽马分布的可加性。![image-20231024194312138](C:\Users\梁云森\AppData\Roaming\Typora\typora-user-images\image-20231024194312138.png)

4. 

##### 应用：

#### 对数伽马分布(Log-Gamma Distribution)

##### 符号：$X \sim \text{log-gamma}(\alpha, \beta)$

##### 概率密度函数：

$$
f(x) = \dfrac{e^{\beta x}e^{-e^{x} / a}}{\alpha^{\beta}\Gamma(\beta)} -\infty < x < +\infty
$$
![image-20231024233520269](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231024233520269.png)

#### 贝塔分布(Beta Distribution)

##### 符号：$X \sim \Beta(\alpha, \beta)$

##### 概率密度函数：

$$
f(x) = \begin{cases}
\dfrac{1}{\Beta(\alpha, \beta)} x^{\alpha - 1}(1-x)^{\beta - 1}, 0 < x < 1 \\
0
\end{cases}
$$
##### 分布函数：

##### 期望：

$$
\begin{aligned}
E(X) &= \int_0^{1}x \cdot \dfrac{1}{\Beta(\alpha, \beta)} x^{\alpha - 1}(1-x)^{\beta - 1} \mathrm{d}x \\
&= \dfrac{\Beta(\alpha + 1, \beta)}{\Beta(\alpha, \beta)} \int_0^{1}\dfrac{1}{\Beta(\alpha + 1, \beta)} x^{(\alpha + 1) - 1}(1-x)^{\beta - 1} \mathrm{d}x \\
&= \dfrac{\Gamma(\alpha + 1)\Gamma(\beta)}{\Gamma(\alpha + \beta + 1)} \cdot \dfrac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \\
&= \dfrac{\alpha}{\alpha + \beta}
\end{aligned}
$$
##### 方差：

$$
\begin{aligned}
E(X^{2}) &= \int_0^{1} \dfrac{1}{\Beta(\alpha, \beta)}x^{(\alpha + 2) - 1}(1 - x)^{\beta - 1} \mathrm{d}x \\
&= \dfrac{\Beta(\alpha + 2, \beta)}{\Beta(\alpha, \beta)} \\
&= \dfrac{\alpha(\alpha + 1)}{(\alpha + \beta)(\alpha + \beta + 1)}
\end{aligned}
$$

$$
D(X) = E(X^{2}) - E(X)^{2} = \dfrac{\alpha \beta}{(\alpha + \beta)^{2}(\alpha + \beta + 1)}
$$

##### 性质：

1. $Beta(1, 1) = U(0, 1)$

##### 应用：

#### 威布尔分布(韦伯分布，Weibull Distribution)

概率密度函数：
$$
f(x;\lambda, k) = \begin{cases}
\dfrac{k}{\lambda}(\dfrac{x}{\lambda})^{k - 1}e^{-(\dfrac{x}{\lambda})^k}, &x \geq 0 \\
0, &x < 0
\end{cases}
$$
其中，x 是随机变量，$\lambda > 0$ 是比例系数(scale parameter)，$k > 0$ 是形状参数(shape parameter)。显然，它的累计分布函数是扩展的指数分布函数。 

##### 期望：

$$
E(X) = \lambda \Gamma(1 + \dfrac{1}{k})
$$
##### 方差：

$$
D(X) = \lambda^{2}\left[\Gamma(1 + \dfrac{2}{k}) - \Gamma^{2}(1 + \dfrac{1}{k})\right]
$$
##### 应用：

威布尔分布在[可靠性工程](https://baike.baidu.com/item/可靠性工程/3129248?fromModule=lemma_inlink)中被广泛应用。

1. 研究生产过程和运输时间关系
2. 预测天气
3. 可靠性和失效分析
4. 雷达系统
5. 对接受的杂波信号依分布建模
6. 量化寿险模型的重复索赔
7. 描述风速分布

#### 瑞利分布(Rayleigh Distribution)

瑞利分布就是两个垂直分量服从独立且均值为0,标准差相同的高斯分布叠加之后的模。
换句话说，复高斯分布的模服从瑞利分布。

[瑞利分布的推导过程 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/573644622) 瑞利分布

#### 柯西分布(柯西-洛伦兹分布，Cauchy Distribution)

##### 符号：$X \sim \text{Cauthy}(a, \alpha)$

##### 概率密度函数：

$$
f(x) = \dfrac{1}{\alpha\pi[1 + ((x - a) / \alpha)^{2}]} \quad \quad -\infty < x < +\infty
$$
![image-20231025112236557](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231025112236557.png)

##### 由来推导：

柯西分布描述了以随机角度倾斜的线段切割 x 轴的水平距离分布。

![image-20231025113546164](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231025113546164.png)
$$
\tan(\theta) = \dfrac{x}{b} \\
\theta = \arctan{\dfrac{x}{b}} \\
\mathrm{d}\theta = \dfrac{1}{1 + \frac{x^{2}}{b^{2}}} \dfrac{\mathrm{d}x}{b}
$$
所以可以使用 $\dfrac{\mathrm{d}\theta}{\pi} = \dfrac{1}{\pi} \dfrac{b\mathrm{d}x}{b^2 + x ^{2}}$ 来计算关于 x 的分布。
$$
\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \dfrac{\theta}{\pi} = 1 \Rightarrow \int_{-\infty}^{+\infty} \dfrac{1}{\pi} \dfrac{b \mathrm{d}x}{b^2 + x^{2}} = 1
$$
所以，$P(X = x) = \dfrac{1}{\pi} \dfrac{b}{(x - m)^{2} + b^2}$

##### 分布函数：

$$
F(x) = P(X \leq x) = \dfrac{1}{2\pi}\left(\pi - 2\arctan(\dfrac{a - x}{\alpha})\right) \quad -\infty < x < +\infty
$$
##### 期望：

不存在

##### 方差：
不存在

##### 应用：

1.  柯西分布，也称为柯西-洛伦兹分布或洛伦兹分布，是描述共振行为的连续分布。它还描述了以随机角度倾斜的线段切割 x 轴的水平距离分布。
2. 在量子世界，粒子和粒子距离很远，比如，电子到原子核的距离，就好比一个汽车到三千公里外的一个城市距离，因此，要显著描述电子的位置分布，只能是柯西-洛伦兹分布，不能用高斯分布刻画，因为高斯分布尺度不够，信号太弱，噪声将把电子的电磁能量淹没，模型无效。

##### 性质：

1.  柯西分布的取值范围非常广，很大的值也有一定概率取到，因而柯西分布也称为heavy-tail distribution。并且相比于gaussian，概率密度的最大取值只有0.1，就是x=0的那个地方。

#### 拉普拉斯分布(双指数分布，Laplace Distribution)

##### 符号：$X \sim \text{Laplace}(\alpha_1, \alpha_2)$

##### 概率密度函数：

$$
f(x) = \begin{cases}
\dfrac{1}{\alpha_1 + \alpha_2}e^{-\frac{x}{\alpha_1}}, &x < 0 \\
\dfrac{1}{\alpha_1 + \alpha_2}e^{-\frac{x}{\alpha_2}}, & x \geq 0
\end{cases}
$$

>The Laplace distribution is an alternative to the normal distribution with heavier tails. The probability density function for three different parameters settings is illustrated below.

![image-20231024230803046](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231024230803046.png)

##### 分布函数：

$$
F(x) = P(X \leq x) = \begin{cases}
\dfrac{\alpha_1}{\alpha_1 + \alpha_2}e^{-\frac{x}{\alpha_1}} &x < 0 \\
1 - \dfrac{\alpha_2}{\alpha_1 + \alpha_2}e^{-\frac{x}{\alpha_2}}&x \geq 0
\end{cases}
$$
##### 期望：

$$
\begin{aligned}
E(X) &= \int_{-\infty}^{0} x \cdot f(x)\mathrm{d}x + \int_0^{+\infty} x \cdot f(x) \mathrm{d}x\\
&= \alpha_2 - \alpha_1
\end{aligned}
$$
##### 方差：

$$
\begin{aligned}
D(X) &= \int_{-\infty}^{0} x^2 \cdot f(x)\mathrm{d}x + \int_0^{+\infty} x^2 \cdot f(x) \mathrm{d}x\\
&= \alpha_1^{2} + \alpha_2^{2}
\end{aligned}
$$
##### 性质：

1. 可看作两平移指数分布背靠背拼接在一起，因此又称双指数分布 (Double exponential distribution)

##### 应用：

#### 玻尔兹曼分布(Boltzmann Distribution)



#### 幂律分布(Power Distribution)

##### 符号：$X\sim \text{Power}(1, \beta)$

##### 概率密度函数：

$$
f(x) = \beta x^{\beta - 1} \quad \quad 0 < x < 1
$$
![image-20231024235040777](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231024235040777.png)

##### 分布函数：

$$
F(x) = P(X \leq x) = x^{\beta}
$$
##### 期望：

$$
E(X) = 
$$
##### 方差：

#### 三角分布(Standard Triangular Distribution)

##### 符号：$X \sim \text{Triangular}(-1, 1, 1)$

##### 概率密度函数：

$$
f(x) = \begin{cases}
x + 1, &-1 < x < 0 \\
1 - x, & 0 \leq x < 1
\end{cases}
$$
![image-20231025114540132](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231025114540132.png)

##### 分布函数：

$$
F(x) = \begin{cases}
\frac{1}{2}x^{2} + x + \frac{1}{2}, &-1 < x < 0 \\
-\frac{1}{2}x^{2} + x + \frac{1}{2}, &0 \leq x < 1
\end{cases}
$$
##### 期望：

$$
E(X) = 0
$$
##### 方差：

$$
D(X) = \dfrac{1}{6}
$$
更一般的，三角形分布是底限为 a，众数为 c，上限为 b 的连续概率分布。
$$
f(x|a, b, c) = \begin{cases}
\dfrac{2(x - a)}{(b - a)(c - a)} \quad a \leq x \leq c \\
\\
\dfrac{2(b - x)}{(b - a)(b - c)} \quad c \leq x \leq b
\end{cases}
$$
![image-20231025124956772](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231025124956772.png)



#### 逻辑斯谛分布(增长分布, Log-Logistic Distribution)

##### 符号：$X \sim \text{loglogistic}(\lambda, \kappa)$

##### 概率密度函数：

$$
f(x) = \dfrac{\lambda\kappa(\lambda\kappa)^{\kappa - 1}}{(1 + (\lambda x)^{\kappa})^{2}} \quad x > 0
$$
![image-20231025130217056](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231025130217056.png)

##### 分布函数：

$$
F(x) = P(X <= x) = \dfrac{(\lambda x)^{\kappa}}{1 + (\lambda x)^{\kappa}}  \quad x > 0
$$
##### 期望：

$$
\begin{aligned}
E(X) &= \int_0^{+\infty} x \cdot f(x) \mathrm{d}x \\
&= \dfrac{1}{\lambda} \int_0^{+\infty}\dfrac{m^{\frac{1}{k}}}{(1+m)^{2}} \mathrm{d}m \\
&= \dfrac{1}{\kappa \lambda} \cdot \dfrac{\pi}{\sin (\frac{\pi}{\kappa})} \\
&= \dfrac{\pi}{\kappa \lambda(\sin (\frac{\pi}{\kappa})}
\end{aligned}
$$
其中，计算的时候可以使用留数定理。

##### 方差：

$$
D(X) = \dfrac{\pi \left(2\kappa(1 - \cos (\frac{\pi}{\kappa})^{2}) + \pi\sin(\frac{\pi(\kappa + 2)}{\kappa}) \right)}{\left(\sin (\frac{\pi(\kappa + 2)}{\kappa}) \right)\left( \cos(\frac{\pi}{\kappa})^{2} - 1\right)(\lambda \kappa)^{2}}
$$

#### 逻辑分布(Logistic Distribution)

##### 符号：$X \sim \text{logistic}(\lambda, \kappa)$

##### 概率密度函数：

$$
f(x) = \dfrac{\lambda^{\kappa}\kappa e^{\kappa x}}{(1 + (\lambda e^{x})^{\kappa})^{2}} \quad -\infty < x < +\infty
$$
![image-20231025134453817](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231025134453817.png)

##### 分布函数：

$$
F(x) = P(X \leq x) = \dfrac{\lambda^{\kappa}e^{\kappa x}}{1 + \lambda^{\kappa}e^{x}} \quad -\infty < x < +\infty
$$
##### 期望：

$$
E(X) = -\ln \lambda
$$
##### 方差：

$$
D(X) = \dfrac{\pi ^{2}}{3\kappa^{2}}
$$

#### t 分布(T Distribution)

如果 $X\sim N(0, 1), Y \sim \chi^{2}(n)$，则有 $Z = \dfrac{X}{\sqrt{\frac{Y}{n}}} \sim t(n)$

##### 概率密度函数：

$$
\begin{aligned}
f(z) =\dfrac{\Gamma(\frac{n + 1}{2})}{\sqrt{n\pi}\Gamma(\frac{n}{2})}\left(\dfrac{z^{2}}{n} + 1\right)^{-\frac{n + 1}{2}}
\end{aligned}
$$
##### 推导：

做变换：
$$
\begin{aligned}
\begin{cases}
u = \dfrac{X}{\sqrt{\frac{Y}{n}}} \\
\\
v = Y
\end{cases}
\end{aligned}
$$
所以有反函数：
$$
\begin{cases}
X = u\sqrt{\dfrac{v}{n}} \\
\\
Y = v
\end{cases}
$$
雅可比行列式是：
$$
|J| = 
$$
所以原问题的分布函数变为：
$$
\begin{aligned}
\iint\limits_{A}f(x,y)\mathrm{d}x\mathrm{d}y &= \iint\limits_{B}f(x(u, v),y(u, v)) |J| \mathrm{d}u \mathrm{d}v \\
&= \int_{-\infty}^{z}\int_{0}^{+\infty}f_X(u\sqrt{\dfrac{v}{u}})f_Y(v) (\dfrac{v}{n})^{-\frac{1}{2}} \mathrm{d}u \mathrm{d}v \\

\end{aligned}
$$
有
$$
\begin{aligned}
f_X(x) = \dfrac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}} \\
f_Y(y) = \dfrac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}y^{\frac{n}{2}- 1}e^{-\frac{y}{2}}
\end{aligned}
$$
所以：
$$
\begin{aligned}
F(Z) &= \int_{-\infty}^{z}\int_0^{+\infty} \dfrac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}u^{2}\frac{v}{n}} \dfrac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}v^{\frac{n}{2} - 1} e^{-\frac{v}{2}}(\dfrac{v}{n})^{-\frac{1}{2}} \mathrm{d}v\mathrm{d}u \\
&= \int_{-\infty}^{z}\dfrac{1}{\sqrt{n\pi}\sqrt{2}}\dfrac{1}{2^{\frac{n}{2}} \Gamma(\frac{n}{2})} \int_0^{+\infty}e^{-\frac{1}{2}u^{2}\frac{v}{n} - \frac{v}{2}}v^{\frac{n - 1}{2}} \mathrm{d}u \mathrm{d}v
\end{aligned}
$$

##### 期望：

$$
E(X) = 0
$$

##### 方差：

$$
V(X) = \dfrac{n}{n - 2}
$$

##### 性质：

##### 应用：

#### F 分布(F Distribution)

F 分布也被称为「方差比分布(Variance Ratio Distribution)」和「Fisher-Snedecor Distribution」。

设 $U \sim \chi^{2}(n_1), V \sim \chi^{2}(n_2)$，并且 U 和 V 相互独立，则称随机变量 $F = \dfrac{U / n_1}{V / n_2}$ 服从自由度为 $(n_1, n_2)$ 的 F 分布

##### 概率密度函数：

$$
f(z) = \dfrac{\Gamma(\frac{n_1 + n_2}{2})(\frac{n_1}{n_2})^{\frac{n_1}{2}}z^{\frac{n_1}{2} - 1}}{\Gamma(\frac{n_1}{2})\Gamma(\frac{n_2}{2})\left[1 + \frac{n_1}{n_2}z\right]^{\frac{n_1 + n_2}{2}}}
$$

##### 推导：

$\text{lemma1}:$ 
$$
f_{\frac{Y}{X}}(z) = \int_{-\infty}^{+\infty}|x|f(x, xz)\mathrm{d}x
$$
$\text{lemma2}:$
$$
f_{aX + b} = \dfrac{1}{|a|}f_X(\dfrac{y - b}{a}) \quad a \neq 0
$$
所以我们可以得到 $Y = \dfrac{U}{n_1}, X = \dfrac{V}{n_2}$ 的概率密度函数为：
$$
f_Y(y) = \dfrac{(\frac{n_1}{2})^{\frac{n_1}{2}}}{\Gamma(\frac{n_1}{2})}y^{\frac{n_1}{2} - 1}e^{-\frac{n_1y}{2}} \quad y > 0
$$

$$
f_X(x) = \dfrac{(\frac{n_2}{2})^{\frac{n_2}{2}}}{\Gamma(\frac{n_2}{2})}y^{\frac{n_2}{2} - 1}e^{-\frac{n_2y}{2}} \quad x > 0
$$

$$
\begin{aligned}
f_F(z) &= f_{\frac{Y}{X}}(z) \\
&= \int_0^{+\infty} xf(x, xz) \mathrm{d}x \\
&= \int_0^{+\infty} xf_Y(xz)f_X(x) \mathrm{d}x \\
&= \int_0^{+\infty} x \dfrac{(\frac{n_1}{2})^{\frac{n_1}{2}}}{\Gamma(\frac{n_1}{2})}(xz)^{\frac{n_1}{2} - 1}e^{-\frac{n_1y}{2}} \cdot  \dfrac{(\frac{n_2}{2})^{\frac{n_2}{2}}}{\Gamma(\frac{n_2}{2})}y^{\frac{n_2}{2} - 1}e^{-\frac{n_2y}{2}} \mathrm{d}x \\
&= \dfrac{(n_1 / 2)^{n_1 / 2}(n_2 / 2)^{n_2 / 2}}{\Gamma(\frac{n_1}{2}) \Gamma(\frac{n_2}{2})}z^{\frac{n_1}{n_2} - 1}\int_0^{+\infty}x^{\frac{n_1 + n_2}{2} - 1}e^{\frac{-x}{2}(n_1z + n_2)} \mathrm{d}x \\
\end{aligned}
$$

设 $u = \dfrac{x}{2}(n_1z + n_2)$

最后得到：
$$
f(z) = \dfrac{\Gamma(\frac{n_1 + n_2}{2})(\frac{n_1}{n_2})^{\frac{n_1}{2}}z^{\frac{n_1}{2} - 1}}{\Gamma(\frac{n_1}{2})\Gamma(\frac{n_2}{2})\left[1 + \frac{n_1}{n_2}z\right]^{\frac{n_1 + n_2}{2}}}
$$

##### 期望：

$$
E(X) = \dfrac{n_2}{n_2 - 2}
$$

##### 方差：

$$
V(X) = \dfrac{2n_2^{2}(n_1+ n_2 - 2)}{n_1}
$$

##### 性质：

1. $F_{1 - \alpha}(n_1, n_2) = \dfrac{1}{F_{\alpha}(n_2, n_1)}$
   证明：
   $$
   \begin{aligned}
   1 - \alpha &= P\{F > F_{1 - \alpha}(n_1, n_2)\} \\
   &= P\{\dfrac{1}{F} < \dfrac{1}{F_{1 - \alpha}(n_1, n_2)}\} \\
   &= 1 - P\{\dfrac{1}{F} \geq \dfrac{1}{F_{1 - \alpha}(n_1, n_2)}\} \\
   &= 1 - P\{\dfrac{1}{F} > \dfrac{1}{F_{1 - \alpha}(n_1, n_2)}\} \\
   \end{aligned}
   $$
   所以 $P\{\dfrac{1}{F} > \dfrac{1}{F_{1 - \alpha}(n_1, n_2)}\} = \alpha$ 并且 $\dfrac{1}{F} \sim F(n_2, n_1)$，所以 $F_{1 - \alpha}(n_1, n_2) = \dfrac{1}{F_{\alpha}(n_2, n_1)}$

2. [F分布概率密度公式推导 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/453635917)

##### 应用：



#### $\chi 分布$(卡方分布, $\chi$ Distribution)

$Z_1, Z_2, ..., Z_k$ 是独立、标准正态分布的随机变量，把他们的平方和记为 Q，则有 $Q = \sum\limits_{i = 1}^{k} Z_i^{2}$

这个 Q 是服从自由度为 K 的卡方分布的。通常会被记为 $Q \sim \chi^{2}(k)$

##### 符号：$Q \sim \chi^{2}(k)$

##### 概率密度函数：

$$
f(x) = \dfrac{1}{2^{\frac{n}{2}}\Gamma(\dfrac{n}{2})}x^{^{\frac{n}{2}} - 1}e^{-\frac{x^{2}}{2}} \quad z > 0
$$

![image-20231026212407458](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231026212407458.png)

##### K 阶矩

$$
\begin{aligned}
E(X^{k}) &= \int_0^{+\infty} x^{k} \cdot \dfrac{1}{2^{\frac{n}{2}}\Gamma(\dfrac{n}{2})}x^{^{\frac{n}{2}} - 1}e^{-\frac{x^{2}}{2}} \mathrm{d}x \\
\end{aligned}
$$

设 $\dfrac{x^{2}}{2}= t$，式子变为：
$$
\begin{aligned}
E(X^{k}) &= \dfrac{2^{\frac{k}{2}}}{\Gamma(\frac{n}{2})}\int_0^{+\infty} t^{\frac{n + k}{2} - 1}e^{-t}\mathrm{d}t \\
&= \dfrac{2^{k / 2}\Gamma(\frac{n + k}{2})}{\Gamma(n / 2)}
\end{aligned}
$$

##### 期望：

$$
E(X) = \dfrac{\sqrt{2}\Gamma(\frac{n + 1}{2})}{\Gamma(n / 2)}
$$

##### 方差：

$$
E(X^{2}) = \dfrac{2\Gamma(n / 2 + 1)}{\Gamma(n / 2)} = n
$$

所以
$$
D(X) = E(X^{2}) - E(X)^{2} = n^{2} - E(X)^{2}
$$

##### 性质：

##### 应用：

#### 狄拉克分布



#### 多项式分布和迪利克雷分布



#### 帕累托分布(布拉德福分布, Pareto Distribution)

这个分布是是从大量真实世界的现象中发现的[幂定律](https://zh.wikipedia.org/wiki/冪定律)分布。这个分布在经济学以外，也被称为**布拉德福分布**。

##### 分布函数：

$$
P(X > x) = \left(\dfrac{x}{x_{\min}} \right)^{-k}
$$

其中，x 是任何一个大于 $x_{\min}$ 的数，$x_{\min}$ 是 X 最小的可能值(正数)。

##### 概率密度：

$$
\begin{aligned}
p(x) = \begin{cases}
0 \quad x < x_{\min} \\
\\
\\
\dfrac{kx_{\min}^{k}}{x^{k + 1}} \quad x > x_{\min}

\end{cases}
\end{aligned}
$$



帕累托分布属于连续概率分布。「齐夫定律」也被称为「Zeta 分布」，也可以被认为是在离散概率分布中的帕累托分布。

![image-20231026223709526](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231026223709526.png)

##### 期望：

$$
E(X) = \int_0^{+\infty} x\cdot f(x) \mathrm{d}x = \dfrac{x_\min k}{k - 1}
$$

##### 方差：

$$
D(X) = \dfrac{x_\min}{k - 1}\sqrt{\dfrac{k}{k - 2}}
$$

##### 应用：

1. 财富在个人之间的分布
2. 人类居住区的大小
3. 对维基百科条目的访问
4. 接近绝对零度时，玻色一爱因斯坦疑聚的团簇
5. 在互联网流量中文件尺寸的分布
6. 油田的石油储备数量
7. 龙卷风带来的灾难的数量

##### 引申：

帕累托法则(Pareto Principle)，或者叫做「二八定律」，「关键少数法则」，「巴莱多定律」。这个定律指出，约仅有 20% 的因素影响了 80% 的结果。也就是说，所有变因中，最重要的仅有 20%，虽然剩余的 80% 占了大多数。

#### 反正弦分布(Arcsin Distribution)

##### 符号：$X \sim \text{arcsin}(x)$

##### 概率密度函数：

$$
f(x) = \dfrac{1}{\pi \sqrt{x(1 - x)}} \quad 0 < x < 1
$$

![image-20231026220704838](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231026220704838.png)

##### 累计分布函数：

$$
F(x) = P(X \leq x) = \dfrac{\pi + 2\arcsin(2x - 1)}{2\pi}
$$

##### 期望：

$$
E(X) = \dfrac{1}{2}
$$

##### 方差：

$$
D(X) = \dfrac{1}{8}
$$

##### 性质：

对于积分 $\int_{a}^{b}\dfrac{\mathrm{d}x}{\sqrt{(x - a)(b - x)}}$ 它的结果是$\pi$

对于这样类型的积分，我们一般是通过换元进行计算 $x  =a\cos^{2}\theta + b\sin^{2}\theta$，那么原来的积分可以变为一个简单的积分：
$$
\int_a^{b}\dfrac{\mathrm{d}x}{\sqrt{(x - a)(b - x)}} = 2\int_0^{\frac{\pi}{2}} \mathrm{d}\theta = \pi
$$
对于这个式子的含义继续深究

![image-20231026221614582](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231026221614582.png)

所以原来的定积分就正好代表了上半圆的弧长，也就是整个圆的半周长。

![image-20231026221707845](C:\Users\24964\AppData\Roaming\Typora\typora-user-images\image-20231026221707845.png)

### 参考

https://zhuanlan.zhihu.com/p/517424307

https://zhuanlan.zhihu.com/p/164883777

[常见分布的数学期望和方差及相关证明 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/449733211)

https://zhuanlan.zhihu.com/p/578567547 特征函数推导

https://zhuanlan.zhihu.com/p/353187472 https://www.zhihu.com/question/354825596/answer/893242882 指数分布

https://zhuanlan.zhihu.com/p/503557666 正态分布

怎么来理解伽玛（gamma）分布？ - 知之的回答 - 知乎 https://www.zhihu.com/question/34866983/answer/60191363 伽马分布和其他分布之间的关系

伽马分布，指数分布，卡方分布之间的关系及期望，方差 - 拾柒的文章 - 知乎 https://zhuanlan.zhihu.com/p/379131967

[深入理解高斯分布 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/303359921) 多元高斯分布

[混合高斯分布与其参数估计 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/596023351) 混合高斯分布

