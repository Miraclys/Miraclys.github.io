<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nunito:300,300italic,400,400italic,700,700italic%7Cfira+code:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="The key record of python crawler.">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫">
<meta property="og:url" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Miraclys">
<meta property="og:description" content="The key record of python crawler.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/%E8%AF%BB%E5%8F%96%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%9E%8B.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/%E8%AF%BB%E5%8F%96%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%9E%8B.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/os%E6%A8%A1%E5%9D%97.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/xpath.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/%E6%9C%AA%E7%9F%A5%E8%8A%82%E7%82%B9.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/%E9%87%8F%E8%AF%8D.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/html%E4%BB%A3%E7%A0%81.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/selenium%E5%AE%9A%E4%BD%8D%E5%85%83%E7%B4%A0.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/%E9%BC%A0%E6%A0%87%E6%93%8D%E4%BD%9C.png">
<meta property="og:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/%E9%94%AE%E7%9B%98%E6%93%8D%E4%BD%9C.png">
<meta property="article:published_time" content="2023-09-04T07:18:39.000Z">
<meta property="article:modified_time" content="2024-02-20T15:04:29.514Z">
<meta property="article:author" content="Miraclys">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/%E8%AF%BB%E5%8F%96%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%9E%8B.png">


<link rel="canonical" href="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/","path":"2023/09/04/python爬虫/","title":"python爬虫"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>python爬虫 | Miraclys</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Miraclys</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E8%A7%86%E9%A2%91"><span class="nav-number">1.</span> <span class="nav-text">学习视频</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%86%E5%88%AB%E7%BD%91%E9%A1%B5%E6%89%80%E7%94%A8%E6%8A%80%E6%9C%AF"><span class="nav-number">2.</span> <span class="nav-text">识别网页所用技术</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python-%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6"><span class="nav-number">3.</span> <span class="nav-text">python 读写文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python-requests-%E6%A8%A1%E5%9D%97"><span class="nav-number">4.</span> <span class="nav-text">python requests 模块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#get-%E6%96%B9%E6%B3%95"><span class="nav-number">5.</span> <span class="nav-text">GET 方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python-%E6%A0%87%E5%87%86%E5%BA%93-os-%E6%A8%A1%E5%9D%97"><span class="nav-number">6.</span> <span class="nav-text">python 标准库 os 模块</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#xpath"><span class="nav-number">7.</span> <span class="nav-text">XPath</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">8.</span> <span class="nav-text">正则表达式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#re-%E5%BA%93"><span class="nav-number">9.</span> <span class="nav-text">RE 库</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="nav-number">9.1.</span> <span class="nav-text">常用函数</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#url-%E7%9A%84%E7%BB%84%E6%88%90"><span class="nav-number">10.</span> <span class="nav-text">url 的组成</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python-urllib-%E5%BA%93"><span class="nav-number">11.</span> <span class="nav-text">python urllib 库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#urlerrorhttperror"><span class="nav-number">12.</span> <span class="nav-text">URLError&#x2F;HTTPError</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#handler-%E5%A4%84%E7%90%86%E5%99%A8"><span class="nav-number">13.</span> <span class="nav-text">Handler 处理器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%90%86"><span class="nav-number">13.1.</span> <span class="nav-text">代理</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python-%E7%88%AC%E5%8F%96%E5%9B%BE%E7%89%87%E7%AE%80%E5%8D%95%E7%A4%BA%E4%BE%8B"><span class="nav-number">14.</span> <span class="nav-text">python 爬取图片简单示例</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E6%9E%90"><span class="nav-number">15.</span> <span class="nav-text">解析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#lxml-%E5%BA%93"><span class="nav-number">16.</span> <span class="nav-text">lxml 库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#jsonpath"><span class="nav-number">17.</span> <span class="nav-text">Jsonpath</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#beautifulsoup-%E7%A4%BA%E4%BE%8B"><span class="nav-number">18.</span> <span class="nav-text">BeautifulSoup 示例、</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#selenium"><span class="nav-number">19.</span> <span class="nav-text">Selenium</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BB%B6%E6%97%B6%E7%AD%89%E5%BE%85"><span class="nav-number">19.1.</span> <span class="nav-text">延时等待</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AF%B9-cookie-%E7%9A%84%E6%93%8D%E4%BD%9C%E4%BA%A6%E7%A7%B0%E4%B8%BA-http-cookie"><span class="nav-number">19.2.</span> <span class="nav-text">对 Cookie 的操作(亦称为 Http
Cookie)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#selenium-%E5%92%8C-splinter"><span class="nav-number">20.</span> <span class="nav-text">selenium 和 splinter</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scrapy-%E6%A1%86%E6%9E%B6"><span class="nav-number">21.</span> <span class="nav-text">Scrapy 框架</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Miraclys"
      src="/../images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Miraclys</p>
  <div class="site-description" itemprop="description">Live a life you will remember.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">58</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Miraclys" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Miraclys" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:miraclysyunsenl@gmail.com" title="E-Mail → mailto:miraclysyunsenl@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/09/04/python%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/../images/avatar.jpg">
      <meta itemprop="name" content="Miraclys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Miraclys">
      <meta itemprop="description" content="Live a life you will remember.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="python爬虫 | Miraclys">
      <meta itemprop="description" content="The key record of python crawler.">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          python爬虫
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-09-04 15:18:39" itemprop="dateCreated datePublished" datetime="2023-09-04T15:18:39+08:00">2023-09-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-20 23:04:29" itemprop="dateModified" datetime="2024-02-20T23:04:29+08:00">2024-02-20</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2023/09/04/python%E7%88%AC%E8%99%AB/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2023/09/04/python爬虫/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

            <div class="post-description">The key record of python crawler.</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4 id="学习视频">学习视频</h4>
<p>B
站：https://www.bilibili.com/video/BV1Db4y1m7Ho/?p=70&amp;share_source=copy_web&amp;vd_source=ca842ea19ddf18fb9427fb4d903d435a</p>
<h4 id="识别网页所用技术">识别网页所用技术</h4>
<p>构建网站所用的技术类型会对我们如何爬取信息产生影响。有一个十分有用的工具可以检查网站构建的技术类型--detectem
模块，该模块需要 python3.5+ 环境以及 Docker</p>
<h4 id="python-读写文件">python 读写文件</h4>
<ol type="1">
<li>open() + close() <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#先打开文件：</span><br><span class="line">f = open(&#x27;C:\\Users\\Administrator\\Desktop\\测试文件.txt&#x27;,&#x27;r&#x27;,encoding = &#x27;utf-8&#x27;)</span><br><span class="line"></span><br><span class="line">#再使用read()方法，查看文件里的内容：</span><br><span class="line">print(f.read())</span><br><span class="line"></span><br><span class="line">$关闭文件</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure> 注意如果使用
<code>open</code>，结尾一定要使用close（）来关闭文件。原因主要是：</li>
</ol>
<ul>
<li>节约资源和内存耗损；</li>
<li>可以释放所占用的系统资源并尽早将文件置于更安全的状态，只有关闭文件后，文件内容才能同步到磁盘。</li>
</ul>
<ol start="2" type="1">
<li><code>with open</code> 推荐使用 with
的作用相当于调用close（）方法，因此当我们使用with open(
)在对文件操作完成后，无需通过close()关闭文件，文件会自动关闭，这种方法的安全系数更高，同时也避免了有些时候忘记关闭文件的毛病。
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with open(&#x27;file_name&#x27;,&#x27;r&#x27;,encoding = &#x27;utf-8&#x27;) as f:</span><br></pre></td></tr></table></figure> <img src="/2023/09/04/python%E7%88%AC%E8%99%AB/%E8%AF%BB%E5%8F%96%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%9E%8B.png" class=""> <img src="/2023/09/04/python%E7%88%AC%E8%99%AB/%E8%AF%BB%E5%8F%96%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%9E%8B.png" class=""></li>
</ol>
<h4 id="python-requests-模块">python requests 模块</h4>
<p>python requests 是一个常用的 HTTP 请求库，可以方便地向网站发送 HTTP
请求，并获取响应结果。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.get(url=url, headers=headers)</span><br></pre></td></tr></table></figure> 返回一个 response
对象，该对象包含了具体的响应信息，如状态码、响应头(200 OK 404
NotFound)、响应内容等。 对于其中的content 和 text
属性(通过输出我们可以看到，content 的输出最开始有一个字母
b，表示输出的格式为二进制，所以我们需要重新编码)</p>
<blockquote>
<p>content中间存的是字节码，而text中存的是Beautifulsoup根据猜测的编码方式将content内容编码成字符串。直接输出content，会发现前面存在b'这样的标志，这是字节字符串的标志，而text是，没有前面的b,对于纯ascii码，这两个可以说一模一样，对于其他的文字，需要正确编码才能正常显示。大部分情况建议使用.text，因为显示的是汉字，但有时会显示乱码，这时需要用.content.decode('utf-8')，中文常用utf-8和GBK，GB2312等。这样可以手工选择文字编码方式。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line"># 发送GET请求</span><br><span class="line">url = &#x27;https://example.com/some-page&#x27;</span><br><span class="line">response = requests.get(url)</span><br><span class="line"></span><br><span class="line"># 尝试获取内容的编码方式</span><br><span class="line">encoding = response.apparent_encoding ## 来尝试获取爬取内容的编码方式。这个属性会尝试根据响应内容来猜测编码方式，通常用于解决服务器没有显式提供编码信息的情况。</span><br><span class="line"></span><br><span class="line"># 设置编码方式并解码内容</span><br><span class="line">content = response.content</span><br><span class="line">text = content.decode(encoding)</span><br><span class="line"></span><br><span class="line"># 打印内容</span><br><span class="line">print(text)</span><br></pre></td></tr></table></figure>
<p>通过这种方式，我们一般可以爬取网页的 <code>html</code> 代码。</p>
<h4 id="get-方法">GET 方法</h4>
<p>其中有三个参数，url，params 和 kwargs，params 传递 get 卸载 URL
中的参数即可。kwargs 我们常写请求头。</p>
<h4 id="python-标准库-os-模块">python 标准库 os 模块</h4>
<p>Python的os模块是一个用于与操作系统交互的内置模块。它提供了许多功能，允许你执行各种文件和目录操作，例如创建、删除、移动和重命名文件和目录，以及检查文件和目录的属性。下面是一些os模块的常见用法和功能：
1. 获取当前工作目录(current work directory) <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">current_directory = os.getcwd()</span><br><span class="line">print(current_directory)</span><br></pre></td></tr></table></figure> 2.
列出目录中的文件和子目录 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">files_and_dirs = os.listdir(&#x27;/path/to/directory&#x27;)</span><br><span class="line">print(files_and_dirs)</span><br></pre></td></tr></table></figure> 3. 创建目录 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.mkdir(&#x27;/path/to/new_directory&#x27;)</span><br></pre></td></tr></table></figure> 4.
删除目录 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.rmdir(&#x27;/path/to/directory_to_delete&#x27;)</span><br></pre></td></tr></table></figure> 5. 检查文件或者目录是否存在 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if os.path.exists(&#x27;/path/to/file_or_directory&#x27;):</span><br><span class="line">    print(&quot;存在&quot;)</span><br><span class="line">else:</span><br><span class="line">    print(&quot;不存在&quot;)</span><br></pre></td></tr></table></figure> 其他 os
模块 <img src="/2023/09/04/python%E7%88%AC%E8%99%AB/os%E6%A8%A1%E5%9D%97.png" class=""></p>
<h4 id="xpath">XPath</h4>
<p>XPath（XML Path
Language）是一种用于在XML文档中定位和选择元素的查询语言。它是一种重要的标准，广泛用于XML文档的解析和数据提取。XPath不仅可以用于XML文档，还可以用于HTML文档，因此它在Web开发和数据抓取中也非常有用。
(感觉可能类似于正则表达式？只是另一种不同的方式) <img src="/2023/09/04/python%E7%88%AC%E8%99%AB/xpath.png" class="">
<img src="/2023/09/04/python%E7%88%AC%E8%99%AB/%E6%9C%AA%E7%9F%A5%E8%8A%82%E7%82%B9.png" class=""></p>
<h4 id="正则表达式">正则表达式</h4>
<p><code>Regular Expression</code> 或者简称 <code>regex, RE</code>.
它的设计思想是用一种<strong>描述性的语言</strong>来给字符串定义一个规则，凡是符合规则的字符串，我们就认为它“匹配”了，否则，该字符串就是不合法的。</p>
<h4 id="re-库">RE 库</h4>
<p>RE 库就是正则表达式库，通过 RE
库我们可以匹配某些特定字符串的一些内容，比如爬虫爬取网页的时候，通过 RE
库可以获取网页内容中的某些特定标签内容。 量词： <img src="/2023/09/04/python%E7%88%AC%E8%99%AB/%E9%87%8F%E8%AF%8D.png" class=""> 字符类：
- <code>[]</code>: 匹配括号内的任意一个字符。例如 <code>[abc]</code>
匹配字符 a、b 或者 c - <code>[^ ]</code>:
匹配括号内字符以外的任意一个字符。例如 [^abc] 就是除了
a、b或者c以外的任意字符。 <img src="/2023/09/04/python%E7%88%AC%E8%99%AB/%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6.png" class=""></p>
<h5 id="常用函数">常用函数</h5>
<ul>
<li><code>re.search(pattern, string, flags=0)</code>
在字符串中搜索第一个匹配的模式，并返回一个匹配对象。</li>
<li><code>re.match(pattern, string, flags=0)</code>
在字符串的开头匹配模式，并返回一个匹配对象。</li>
<li><code>re.findall(pattern, string, flags=0)</code>
返回一个包含所有匹配项的列表。</li>
<li><code>re.sub(pattern, repl, string, count=0, flags=0)</code>
用指定的替换字符串替换匹配的文本。</li>
<li><code>re.split(pattern, string, maxsplit=0, flags=0)</code>
根据模式拆分字符串。 其中 <code>flags</code>
是标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。
&gt; 在Python中，前缀r表示一个原始字符串（raw
string）。原始字符串中的反斜杠字符，而不会被解释为转义字符。这在处理正则表达式等包含大量反斜杠的字符串时非常有用，因为正则表达式模式本身通常包含许多反斜杠，这些反斜杠需要被保留而不被解释为转义字符。</li>
</ul>
<h4 id="url-的组成">url 的组成</h4>
<p>http 协议的端口号一般是 80，https 是 443</p>
<p>分别是 协议、主机、端口号、路径、参数和锚点</p>
<p>User Agent 简称
UA，中文名位用户代理，是一个特殊的字符串头，使得服务器识别用户使用的操作系统及版本、CPU
类型、浏览器版本、浏览器内核、浏览器渲染引擎、浏览器语言和浏览器插件。</p>
<p>我们可以直接百度 UA 大全获得常用的 UA</p>
<p>为了添加 UA，我们可以定制一个 Request</p>
<h4 id="python-urllib-库">python urllib 库</h4>
<p>urrlib 中常用的方法</p>
<p>先创建一个 response 类
<code>response = urrlib.request.urlopen(url)</code></p>
<ol type="1">
<li>reponse.read()
返回按照字节读取的结果，如果我们想改变编码方式加上一个 decode 就可以
如果是写 <code>reponse.read(5)</code> 就是读取了前 5 个字节</li>
<li>reponse.readline() 读取一行、</li>
<li>reponse.readlines() 返回一个 list，包含所有的行</li>
<li>reponse.getcode() 返回状态码，如果是 200 表示没有问题</li>
<li>reponse.geturl() 返回的是 url 地址</li>
<li>reponse.headers() 获得的响应头，包含很多状态信息</li>
<li>urllib.request.urlretrieve(url=url, filename='xxx') 可以下载 url
地址的文件下来</li>
</ol>
<p>其中，urllib.request.urlopen(xxx) 函数，其中的 xxx 可以是一个
url（也就是一串字符串），也可以是一个 Request 对象（包含 url，headers
等一些其余的参数）</p>
<p>如果我们使用协议为 https，但是不加
UA，返回的内容会很少，因为有反爬机制，但是如果使用 http
协议就没有问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line"></span><br><span class="line">url = &#x27;https://www.baidu.com&#x27;</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36&#x27;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">print(response.read().decode(&#x27;utf-8&#x27;))</span><br></pre></td></tr></table></figure>
<p>我们可以使用 urllib.parse.quote('xxx') 来将一段文字转换为 url
中的格式。如果我们需要同时转换多个属性或者说文字，可以使用
urllib.parse.urlencode('xxx')。其中，xxx 是一个参数的字典。</p>
<p>注意使用 GET 方法和 POST 方法时，传递参数的不同</p>
<h4 id="urlerrorhttperror">URLError/HTTPError</h4>
<p>两个异常类，URLError 和 HTTPError</p>
<p>因为我们知道在 URL 结构中包括 HTTP 协议，所以这里的异常类，HTTPError
其实是 URLError 的一个子类。</p>
<h4 id="handler-处理器">Handler 处理器</h4>
<p>Handler 可以定制更高级的请求头（相比直接的 headers），比如说动态
cookie 和代理</p>
<h5 id="代理">代理</h5>
<p>代理的常用功能： 1. 突破自身 ip 限制，访问国外的一些站点 2.
访问一些单位或者团体内部的资源 3.
提高访问速度，通常代理服务器有一个较大的硬盘缓冲区，当其他用户访问相同信息的时候，则从缓冲区中直接取出信息，提高访问速度。
4. 隐藏真实 ip，上网者可以通过这种方式隐藏自己的 ip，免受攻击</p>
<h4 id="python-爬取图片简单示例">python 爬取图片简单示例</h4>
<p>我们打开一个下载图片的网址 https://pic.netbian.com/new/
我们向这个网站发送请求以后获得的 <code>text</code> 就是网站的
<code>html</code> 代码。我们分析一下其中的 <code>html</code> 代码
<img src="/2023/09/04/python%E7%88%AC%E8%99%AB/html%E4%BB%A3%E7%A0%81.png" class=""> 其中的 <code>/uploads/allimg/xxx</code>
就是我们的图片的具体地址。 我们可以使用正则表达式(re 库)来获取
<code>html</code> 代码中所有符合图片格式的地址，然后存储到
<code>img</code> 中。再向图片的具体地址发送请求，此时我们使用 python
的文件读写(二进制模式)，就可以批量地将图片下载下来了。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import os</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">url = &quot;https://pic.netbian.com/&quot;</span><br><span class="line">headers = &#123;</span><br><span class="line">    &quot;user-agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&quot;</span><br><span class="line">&#125;</span><br><span class="line">response = requests.get(url=url, headers=headers)</span><br><span class="line">encoding = response.apparent_encoding</span><br><span class="line">content = response.content</span><br><span class="line">text = content.decode(encoding)</span><br><span class="line">parr = re.compile(&#x27;src=&quot;(/u.*?)&quot;.alt=&quot;(.*?)&quot;&#x27;) # 匹配图片链接和图片名字 使用正则表达式</span><br><span class="line">image = re.findall(parr, text) # 所有的图片链接</span><br><span class="line">path = &quot;photos&quot;</span><br><span class="line">if not os.path.isdir(path):</span><br><span class="line">    os.mkdir(path)</span><br><span class="line">for i in image:</span><br><span class="line">    link = i[0]</span><br><span class="line">    name = i[1]</span><br><span class="line">    with open(path+&quot;/&#123;name&#125;.jpg&quot;.format(name),&quot;wb&quot;) as img:</span><br><span class="line">        res = requests.get(&quot;https://pic.netbian.com&quot; + link)</span><br><span class="line">        img.write(res.content)</span><br><span class="line">        img.close()</span><br><span class="line">    print(name+&quot;.jpg 获取成功......&quot;)</span><br></pre></td></tr></table></figure>
爬取王者荣耀头像，感觉写的很丑很傻。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import os</span><br><span class="line">url = &quot;https://pvp.qq.com/web201605/herolist.shtml&quot;</span><br><span class="line">headers = &#123;</span><br><span class="line">    &quot;user-agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, &quot;</span><br><span class="line">                  &quot;like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&quot;</span><br><span class="line">&#125;</span><br><span class="line">response = requests.get(url=url, headers=headers)</span><br><span class="line">encode = response.apparent_encoding</span><br><span class="line">text = response.content.decode(encode)</span><br><span class="line">pattern = re.compile(r&#x27;(//game.+\.jpg)&#x27;)</span><br><span class="line">pattern1 = re.compile(r&#x27;alt=&quot;(.+?)&quot;&#x27;)</span><br><span class="line">images = re.findall(pattern, text)</span><br><span class="line">names = re.findall(pattern1, text)</span><br><span class="line">path = &quot;heroes&quot;</span><br><span class="line">if not os.path.exists(path):</span><br><span class="line">    os.mkdir(path)</span><br><span class="line">cnt = 0</span><br><span class="line">for element in images:</span><br><span class="line">    cur = element</span><br><span class="line">    with open(path + &quot;/&#123;&#125;.jpg&quot;.format(names[cnt]), &quot;wb&quot;) as img:</span><br><span class="line">        res = requests.get(&quot;https:&quot; + cur)</span><br><span class="line">        img.write(res.content)</span><br><span class="line">        img.close()</span><br><span class="line">    print(&quot;捕获成功&quot;)</span><br><span class="line">    cnt = cnt + 1</span><br></pre></td></tr></table></figure></p>
<h4 id="解析">解析</h4>
<p>上面我们都是对于一个接口或者一个网页进行 request
操作。但是有时候我们想得到网页上的若干内容，这就需要我们对于网页进行解析。</p>
<p>市场中，比较主流的解析方式有三种，Xpath、Jsonpath 和
BeautifulSoup。正则的话是比较少用的，因为使用正则表达式解析复杂的HTML或XML结构可能会变得笨拙和容易出错。</p>
<h4 id="lxml-库">lxml 库</h4>
<p>lxml 库是一个使用 python 编写的库，可以迅速、灵活地处理 XML 和
HTML。</p>
<p>其中 lxml.etree 模块是最常用的 HTML、XML
文档解析模块。其中lxml.etree.Element是处理xml的一个核心类，Element对象可以直观的理解为是XML中的节点。使用Element类，可以实现对XML节点、节点属性、节点内文本的操作。</p>
<p>https://blog.csdn.net/weixin_57440207/article/details/116363166 lxml
库的基本使用。</p>
<p>示例代码 <code>zhanzhangsucai_jpg.py</code></p>
<h4 id="jsonpath">Jsonpath</h4>
<p>JsonPath 可以解析 json
格式的内容，帮助我们快速定位到特定的节点或值。</p>
<p>JsonPath 只可以解析本地的 json 文件，但是 XPath
可以解析网络上获取的内容或者本地的 HTML，这一方面两者有一些区别</p>
<h4 id="beautifulsoup-示例">BeautifulSoup 示例、</h4>
<p>相比直接使用 XPath，bs4
的接口更加人性化，我们使用更加方便。但是相比其他的解析库如
lxml，BeautifulSoup 的速度可能会比较慢，因为它是纯用 python
编写的，而不是 C 语言。</p>
<p>所以说，很多时候我们并不选择使用 bs4，即使它比较简单，但是比较慢</p>
<p>上面的都是比较基础的，对于一些动态的网页结构还是无能为力的。
我们可以使用 python <code>bs4</code> 库的 <code>BeautifulSoup</code>
库来对于请求后获得的 <code>html</code> 文本进行解析。
这是一段爬取豆瓣网站上<code>电影top250</code>的电影名称。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">headers = &#123;</span><br><span class="line">    &quot;user-agent&quot;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 &#x27;</span><br><span class="line">                  &#x27;(KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69&#x27;</span><br><span class="line">&#125;</span><br><span class="line">for page_num in range(0, 250, 25):</span><br><span class="line">    url = f&quot;https://movie.douban.com/top250?start=&#123;page_num&#125;&amp;filter=&quot;</span><br><span class="line">    response = requests.get(url=url, headers=headers)</span><br><span class="line">    encode = response.apparent_encoding</span><br><span class="line">    content = response.content.decode(encode)</span><br><span class="line">    html = BeautifulSoup(content, &#x27;lxml&#x27;)</span><br><span class="line">    titles = html.findAll(&quot;span&quot;, attrs=&#123;&quot;class&quot;: &quot;title&quot;&#125;)</span><br><span class="line">    for title in titles:</span><br><span class="line">        if &#x27;/&#x27; not in title.string:</span><br><span class="line">            print(title.string)</span><br></pre></td></tr></table></figure>
我们通过 <code>BeatifulSoup(content, 'lxml')</code> 获取的是一个
BeatifulSoup 解析得到的结构。 其中 content 就是我们请求网站获得的 html
代码，后面的 <code>lxml</code> 是一个 html
的解析器，我们需要手动指定解析器，因为 BeautifulSoup 不仅仅可以解析
html。 <code>html = BeautifulSoup(content, 'lxml')</code> 获得到的
html，有许多的方法。 其中如果我们想获得哪一元素，比如说段落，就可以直接
<code>html.findAll("p")</code> 返回的是一个可以迭代的对象。如果直接写
<code>html.find("p")</code> 则是获得的第一个段落元素。
如果我们仍想要对于段落进一步细化，我们可以在后面加上参数，其中的格式是若干组键值。比如，我们想获取类名为<code>title</code>的span，就可以写为
<code>titles = html.findAll("span", attrs=&#123;"class": "title"&#125;)</code>
对于提取到的元素，我们会获得一个 <code>bs4.element.Tag</code> 就是一个
bs4 中的 Tag 对象，比如说我们有一个 <code>cur</code> 是
<code>bs4.elemnt.tag</code> 对象。 <code>cur.name</code>
就是输出标签的名字，比如 <code>p</code> <code>img</code>
<code>div</code> 如果我们想要获得里面的单个属性值，就直接
<code>cur['xx']</code> 或者
<code>cur.get('xx')</code>，如果我们想获取全部的属性值，就是
<code>cur.attrs</code> 获得标签内的文本，<code>cur.get_text()</code></p>
<h4 id="selenium">Selenium</h4>
<p>前面都是模拟发送一个 <code>request</code>
获得返回，下面是真是模拟我们打开浏览器后进行操作。 Python 中的 Selenium
是一个用于自动化网页操作和测试的强大工具。它提供了一种方式来模拟用户在浏览器中的操作，例如打开网页、填写表单、点击按钮、抓取数据等。
Selenium 的核心之一就是
WebDriver，它是一个接口，允许我们与不同的浏览器进行交互。我们需要下载与我们所使用浏览器相对应的
WebDriver 驱动程序。将 WebDriver 的路径指定为您的 Python 脚本中。</p>
<p>下面是一段打开百度首页并且搜索「你好」的代码。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">import time</span><br><span class="line">from selenium.webdriver.common.by import By # 使用 find_element by=xxx 一定要引入这个</span><br><span class="line">driver = webdriver.Chrome()</span><br><span class="line">driver.get(&#x27;https://www.baidu.com&#x27;)</span><br><span class="line">driver.find_element(by=By.ID, value=&#x27;kw&#x27;).send_keys(&#x27;你好&#x27;)</span><br><span class="line">driver.find_element(by=By.ID, value=&#x27;su&#x27;).click()</span><br><span class="line">time.sleep(5)</span><br></pre></td></tr></table></figure>
下面是查找元素的 by 赋值情况，后面的 <code>value</code>
就是目标的索引值。这是新版本的 <code>find</code> 操作，之前的
<code>find_element_by</code> 方法现在已经弃用。 <img src="/2023/09/04/python%E7%88%AC%E8%99%AB/selenium%E5%AE%9A%E4%BD%8D%E5%85%83%E7%B4%A0.png" class=""></p>
<p>对于查找后，如果是 <code>find_elements</code>
得到的是一个链表，如果是 <code>find_element</code> 得到的是一个
<code>&lt;class 'selenium.webdriver.remote.webelement.WebElement'&gt;</code>，后面对于这个类元素，我们可以
<code>xxx.click()</code> 点击 <code>xxx.send_keys("xxx")</code> 发送信息
<code>xxx.text</code> 获取文本 <code>xxx.clear()</code> 清除元素内容 如
input 中的内容 <code>get_attribute("value")</code>
获得<code>value</code>的属性值 <code>current_url</code>
可以获取当前页面的 url</p>
<p>下面是更深入的对于鼠标和键盘 模拟鼠标操作需要读入类
<code>ActionChains</code>
<code>from selenium.webdriver.common.action_chains import ActionChains</code>
<img src="/2023/09/04/python%E7%88%AC%E8%99%AB/%E9%BC%A0%E6%A0%87%E6%93%8D%E4%BD%9C.png" class=""></p>
<p>模拟键盘操作的话，也需要导入键盘的类
<code>from selenium.webdriver.common.keys import Keys</code>
<img src="/2023/09/04/python%E7%88%AC%E8%99%AB/%E9%94%AE%E7%9B%98%E6%93%8D%E4%BD%9C.png" class=""></p>
<h5 id="延时等待">延时等待</h5>
<p>遇到使用ajax加载的网页，页面元素可能不是同时加载出来的，这个时候尝试在get方法执行完成时获取网页源代码可能并非浏览器完全加载完成的页面。所以，这种情况下需要设置延时等待一定时间，确保全部节点都加载出来。
有三种方式： 1. 强制等待 直接 <code>time.sleep(xx)</code>(记得先导入包
<code>import time</code>) 2. 隐式等待 <code>implicitly_wait(xx)</code>
设置等待时间，如果到时间还有元素没有加载出来就会抛出异常。 3. 显式等待
设置一个等待时间和等待条件，在规定时间内，每隔一段时间查看下条件是否成立，如果成立那么程序就继续执行，否则就抛出一个超时异常。</p>
<h5 id="对-cookie-的操作亦称为-http-cookie">对 Cookie 的操作(亦称为 Http
Cookie)</h5>
<p>Cookie
通常用于在客户端（浏览器）和服务器之间存储一些小型数据，以便在用户与网站进行交互时进行识别、跟踪和状态管理。
 爬虫中常常使用 selenium + requests 实现
cookie持久化，即先用 selenium 模拟登陆获取 cookie ，再通过 requests 携带
cookie 进行请求。 <code>webdriver</code> 提供 cookie
的几种操作：读取、添加和删除。 1.
get_cookies：以字典的形式返回当前会话中可见的 cookie 信息。 2.
get_cookie(name)：返回 cookie 字典中key == name 的 cookie 信息 3.
dd_cookie(cookie_dict)：将 cookie 添加到当前会话中 4.
delete_cookie(name)：删除指定名称的单个 cookie 5.
delete_all_cookies()：删除会话范围内的所有cookie</p>
<p>https://blog.csdn.net/kobepaul123/article/details/128796839
https://blog.csdn.net/weixin_50835854/article/details/117170894 selenium
爬取图片 https://zhuanlan.zhihu.com/p/270391233
https://blog.csdn.net/qq_37267676/article/details/111667266
https://zhuanlan.zhihu.com/p/366773104</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver.common.by import By</span><br><span class="line">import time</span><br><span class="line">driver = webdriver.Chrome()</span><br><span class="line">for index in range(0, 250, 25):</span><br><span class="line">    driver.get(f&#x27;https://movie.douban.com/top250?start=&#123;index&#125;&amp;filter=&#x27;)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    list = driver.find_elements(by=By.XPATH, value=&#x27;//div[@class=&quot;pic&quot;]/a/img&#x27;)</span><br><span class="line">    for cur in list:</span><br><span class="line">        print(cur.get_attribute(&#x27;alt&#x27;))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="selenium-和-splinter">selenium 和 splinter</h4>
<p>splinter和selenium都是用于测试网页的程序，可以模拟浏览器操作，进行自动化测试，可以用于爬虫，自动抢票，网页自动化处理等。Selenium是Splinter的底层，Splinter是Selenium的一个上层封装。使用splinter和selenium时也会用到和html，css相关的使用。</p>
<h4 id="scrapy-框架">Scrapy 框架</h4>
<p><code>Scrapy</code> 是一个异步网络 python
爬虫框架，可以高效地处理大量的请求和响应。它能够并行发送HTTP请求，从而加快数据抓取速度。异步处理允许我们同时处理多个请求而无需等待每一个请求的完成，这对于大规模的数据抓取任务十分有用。
它的优势： 1. 内置选择器(Selector)，使用 XPath 或者 CSS
选择器语法，使我们可以轻松获取 HTML 文档中的数据(我们不需要再去使用 bs4
?)。 2. 模块化和可扩展性
允许我们将爬虫任务分解为多个模块，包括爬虫、中间件、管道等，使代码易于维护和扩展。
3. 自动化处理
Scrapy提供了强大的自动化功能，包括请求的调度、URL跟踪、重试失败的请求等。它还支持自动限速，以避免过度请求目标网站，从而遵守网站的使用政策。
4. 内置 HTTP 请求处理
Scrapy可以处理HTTP请求和响应的所有细节，包括Cookies、User-Agent、重定向、状态码处理等。这减轻了用户的负担，让你专注于爬取和数据处理。</p>
<p>https://www.runoob.com/w3cnote/scrapy-detail.html 上面讲解了 Scrapy
的爬行流程，感觉还是挺形象的。只有当调度器中不存在任何 request
的时候，整个程序才会停止，又因为对于下载失败的 url 会再次进入
scheduler(调度器)，所以对于下载失败的 url，Scrapy 会重新进行下载。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/09/01/CSS%E8%AE%B0%E5%BD%95/" rel="prev" title="CSS记录">
                  <i class="fa fa-angle-left"></i> CSS记录
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/09/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%85%B3%E9%94%AE%E8%AE%B0%E5%BD%95/" rel="next" title="数据结构关键记录">
                  数据结构关键记录 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Miraclys</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  

  <a href="https://github.com/Miraclys" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"miraclys","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
